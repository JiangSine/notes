# Java性能权威指南
---

## 1. 导论
本书主要着眼于两个方面：
- 如何利用JVM自身的性能进行调优， 也可以说如何通过配置JVM来影响程序的各种性能指标。
- 理解Java平台的特性对性能的影响。


**JVM调优标志**
除了少数标志，JVM主要接受两类标志：
1. 布尔标志：-XX:+flagName表示开启， -XX:-flagName表示关闭
2. 带有参数的标志：-XX：flagName=something,表示flagName的值为something.

自动优化:JVM自身会基于环境对标志进行自动调优。

### 1.1全面的性能调优
**算法**
提高性能，算法是重中之重。
**编写更少的代码**
代码量的增多，代表启动时间的增加，代表创建和销毁的对象变多，代表GC的工作量越大，GC的周期越长。

而且，这是一个积少成多的问题。而且很难修复。

**过早优化**
高德纳的名言：
> 不应该话大量的时间耗费在很小的性能提升上。过早优化是所有噩梦的根源。

这句话是说，我们应该编写 **清晰、直接、易读、易理解** 的代码。

但是，优化本身不属于过早优化的层次，当你知道有不同的解决方案，其中一种更加优秀的时候，这是优化，不是过早优化。

**外部环境**
可能外部环境才是瓶颈，是的，我是说数据库。
水桶效应永远适用于有依赖的应用。

### 1.2常见的优化

1. 借助性能分析来优化代码。终点关注耗时的操作。
2. 新代码比起机器配置更可能引起性能问题，机器配置比操作系统或者JVM的bug问题。
3. 为应用最常用的操作编写简单的算法。

## 2. 性能测试

### 2.1 测试真实应用
**微基准测试** 是用来测试微笑代码单元的性能。
但是测试起来很困难。主要是JVM的优化带来的问题。
1. 如果测试结果不被使用，编译器可能会去除计算。实际上，把局部变量变成实例变量并用volatile修饰是更好而办法。
2. 多线程下，有可能更多的时间被花在竞争资源上。
3. 多次执行，可能会被编译器发现并且优化掉。
4. 输入合理的参数，不合理的参数，会导致测试结果答非所问。

除此之外，还要注意的是编译效应，编译器在编译方法时， 会根据代码的性能分析反馈来决定最佳优化策略：频繁调用的方法，调用的栈的深度，方法参数的实际类型。

**宏基准测试** 测试的是应用本身，以及用到的所有资源。
测试的是当前的环境下，了解一个应用的性能。
不进行整体的测试，就不会了解那部分的优化会产生最大的回报。


### 2.2 理解批处理流失时间，吞吐量和响应时间
JIT的存在，让代码的循环执行，不再可以简单的测试。
JVM回花点时间全面优化代码，让其以最高的性能执行。

> 程序热身
> 应用的热身，指的是，在应用实际运行中，会有很多的缓存在工作，他们共同促进的程序快速的运行。



## 3. Java性能调优工具箱

### 3.1 操作系统的工具和分析
监控的是CPU,内存，磁盘的使用，偶尔需要监控的是网络。

**CPU**
性能调优的目的是，让CPU在最短时间内使用率尽可能高。

CPU空闲的原因：
1. 同步原语阻塞，等待锁的释放。
2. 等待某些东西，比如数据库的响应。
3. 的确是无所事事。

**磁盘使用率**
- 如果磁盘正在做大量的I/O操作，那么I/O很容易就会成为瓶颈。
- 监控系统是不是正在做内存交换。

### 3.2 Java监控工具
...

---



## JVM概览
#### HotSpot VM基本构架

HotSpot VM主要分为三个部分，VM运行时，JIT编译器，内存管理器。

早期的hotspot VM是32位的，所以内存空间被限定在4G（2的32次方个地址位空间），但是其实在运用中java堆的大小还会受限于底层的操作系统的限制。

随着时代和技术的发展，64位hotspot VM开始产生，这个就极大的拓展了JVM可以使用的java堆的大小，但是这个也导致了一部分的性能问题，这是由于在CPU中缓存高速缓存中的空间是的一定的，而由于java面向对象的思想策略所以会有大量的对象指针，而随着指针的大小从32位扩展到了64位，所以oops(普通对象指针)能够在高速缓存中的存储数量就会相应的减少，这个会导致CPU的高速缓存的命中率下降，CPU会更多的和内存进行交互这个将会导致大约8%～15%的性能损失。

在JAVA6中这个问题得到了对应的缓解，就是引入了压缩指针，这个新的特性同时继承了32位指针以及64位指针的优势。压缩指针通过对齐以及偏移量将64位指针压缩成32位进行存储。当然更多的CPU寄存器也能够避免发生寄存器卸载（将寄存器的内容转到内存中）

#### HotSpot VM运行时

下面就简单的介绍一下HotSpot VM运行时的几个功能划分的部分

**命令行选项**：JVM运行时系统解析命令行选项，并据此配置选择什么JIT编译器以及选择何种垃圾收集器等。其中一般分为三类，标准，非标准以及非稳定。标准是在所有的JAVA虚拟机都要求实现的，非标准和非稳定都是不强制实现的。

这个命令行选项我们可以理解为我们输入参数解析器，一般来说一个应用的启动将会有不少输入参数的输入，这个时候输入的参数就通过命令行选项进行解析判断并最终产生作用效果。

**VM生命周期管理**：这个部分负责虚拟机的启动和停止，在java虚拟机的启动和停止的步骤中有大量的细节操作。

譬如在启动的时候会：

1. 解析命令行选项
2. 设置对大小和JIT编译器
3. 读取系统环境变量，类似于CLASS_PATH
4. 如果命令行有-jar选项，启动器则从指定的jar包找入口，否则从命令行输入找入口
5. 使用标准java本地接口创建第一个线程并在其中创建Hotspot VM
6. 加载入口类main-class
7. 通过JNI方法CallStaticVoidMethod调用main方法，并将命令行参数传给它

如果应用或者是main方法执行完毕，那么就会清理所有的未处理异常。调用本的接口方法DetachCurrentThread将main和虚拟机脱离。每次调用DetachCurrentThread的时候会导致线程数减一，所以在最终退出的时候能够确保没有正在执行的任务。

**VM类加载**：类加载，指类名或者接口名映射到类对象的整个过程，分为三个阶段加载、链接、初始化。一般来说在使用反射的时候会比较大概率的引发类加载，例如Class.forName(),在JVM启动时不光会加载不少的普通类，还会加载不少核心类Object、Thread之类。事实上加载阶段是Hotspot VM和特定类加载其之间相互协作的过程。

**字节码验证**：java为了做到类型安全在启动的时候会验证所有的类是不是都是由java进行编译产生的，一般分为两种方法类型推导以及类型检查，一般而言小于50的使用推导，大于的使用检查（检查有错会使用推导进行二次检查）

**类数据共享**：就是可以通过预先的加载文档生成，避免每次启动对于部分常用类的重复加载。这些类在生成了共享文档之后，每次启动JVM的时候直接读文件到内存作为数据即可，不再需要重复加载。

**解释器**：Hotspot VM解释器是一种基于模板的解释器，在Hotspot VM的TemplateTable中存储了解释器的信息，包含了每个字节码对应的机器代码，每个模板描述一个字节码。这个就描述了一个事实，就是java在运行的时候有一大部分是通过解释执行的，并没有和我们想象的那样编译执行。

这是由于一个事实，就是系统的大部分时间都是执行的一小部分重复的代码，所以java采取的策略就是将使用频繁的代码编译，其余代码解释执行。

**异常处理**：当java代码遇见运行异常的时候java虚拟机就会通知异常处理程序，一般是通过推展的方法，一直重复直到找到对应的异常处理器，并执行异常处理代码。

**同步**：同步机制是为了保证交替使用的资源的安全性，JVM使用minitor来实现线程运行代码之间的互斥，monitor对象只能被一个线程拥有，只有拥有这个对象的线程才被允许执行对象临界区的代码

HotSpotVM吸收了非竞争和竞争性同步操作的最新技术，极大的提高了同步的效率，通过java5中新增的偏向锁。大多数的同步操作使用称为fast-path代码的方法，由于Hotspot VM有两个编译器和一个解释器，都可以产生fast-path代码，没有竞争时就都通过fast-path进行处理，存在竞争的时候就通过slow-path代码实现。

线程管理：线程管理涉及线程从创建到终止的整个生命周期，线程管理需要管理java代码创建的线程、直接与JVM管理的本地线程以及JVM内部创建的线程。

在HotSpotVM中java线程被一一映射为对应的本地系统线程，当java线程终止的时候本地线程也被收回

JVM内部线程大概有以下几个：
- VM线程
- 周期任务线程
- 垃圾收集线程
- JIT编译器线程
- 信号分发线程

**C++堆管理**：除了HotSpotVM内存管理器和垃圾收集器维护的java堆意外HotspotVM还是用C/C++对存储内部对象和数据，这些类只供HotspotVM使用并不会暴露给应用。Arena及其子类是malloc之上的一层，可以快速进行内存分配。并且在JIT的编译过程中HotSpot的Client和server Jit编译器也会使用Arena

**JAVA本地接口**：java本地接口允许是使用其他语言编写的库进行合作操作，JNI本地方法可以用来创建检测更新java对象、调用java方法捕获并抛出异常。但是注意的是JNI可能会使应用失去一次编译到处运行的特性

**致命错误处理**：致命错误并不是指的代码中抛出的错误，这个错误往往指的是一些JVM内部的错误，比较常见的有outofMemoryError,当出现这种错误的时候JVM都被迫停滞，设计者认为让开发者能够诊断和修复JVM的致命错误的特点非常重要。

---
## HotSpot VM的垃圾收集机制

首先我们需要明确这个知识点，我们在java中所说的垃圾收集机制指的都是在java堆中的垃圾收集。Java虚拟机规范要求所有的JVM都能适当的回收闲置内存，垃圾收集器的运行方式和执行效率对于应用的性能和相应有着极大的影响。

#### 分代垃圾收集
在HotSpot VM中使用分代垃圾收集器，这个逻辑基于以下事实：

- 大多数分配对象的存活时间都非常短

- 存活时间久的对象很少引用存辉时间短的对象

对于大多数应用而言，这个两个特征能够比较明确的得到体现，所以依据这些逻辑，在HotSpot VM中堆中的内容被分为三个部分：

- 新生代：新创建的对象会被分配到这里，对于整个堆而言一般比较小，垃圾收集平凡，并且其中的对象大部分被收集得很快（这里指存活时间比较短）。

- 老年代：在新生代中如果一个对象存活度过一定的周期之后，那么HotSpot VM认为这个对象将会比较长久的存在，那么就会把对象提升到老年代中。老年代的占比比较大，并且其中的垃圾收集次数较少，并且每次收集能够销毁的对象比较少（相对比例而言）

- 永久代：这个虽然称之为代，但是事实上这个部分不与新老两个代进行代际的转移，HotSpot VM只是拿来存放元数据（类的数据结构、保留字符串等）

收集方法，垃圾收集器通过卡表来进行查找老——新之间的引用，将老年代的数据以每512个字节划分为若干个快。每次老年代对象中引用新生代的字段发生变化的时候卡表的状态便被设置为脏，垃圾收集器只需要在脏卡中查找老——新引用的变化。

HotSpot VM字节码解释器和JIT编译器使用些屏障维护卡表，就是一段维护卡表状态的代码，每次在有引用的更新的时候就会执行这段代码，这虽然添加了部分操作量但是极大的减少了垃圾收集器的工作，所以整体上这个还是对于性能有极大的提升的。

分代垃圾收集的办法使得JVM可以通过不同的垃圾收集的策略和算法对于不同特征的堆内容进行特异性的收集，这个对于性能的优化就给我们提供了更多的空间。

#### 新生代
新生代的区域一般来说被分为三块，其中一块为Eden还有两块为Survivor，在这里我们为了方便解说就将Survivor分成S1和S2分别对应两块Survivor

在这里我们提供一个简单的垃圾收集的例子，假设一个垃圾收集就要开始，这个时候依据内存分配的情况Eden，S1中存在对象，S2中空闲。

一般来说新分配的对象都会被生成在Eden中，当某次垃圾收集完成之后，在Eden依然存活的以及在S1中存活的对象会被转移到之前空置的S2中去，将之前有对象的S1和Eden清空。然后直到进行下一次收集，Eden中剩下以及S2中剩下的对象被转移到空闲的S1中去......直到如果在转移过程中发现某些对象存在的时间过程，譬如说已经幸存超过10次垃圾收集，那么这些对象将会被提升到老年代中去。

#### 快速内存分配
有一点可以清楚的看到，就是在之前的垃圾收集（新生代）之后，我们处于Eden中的空间总是空的，所以为了提升内存分配的效率可以直接使用指针碰撞的方法进行内存的快速分配。

在分配开始时只需要检查top和Eden末端之间的空间是否符合需要，如果能够容纳，那么就直接分配空间出去，并把top指针往后移动至分配出去的空间之末。

> 注：在这里由于java是一个允许多线程的语言，所以实际操作的时候是给予每个线程一个Eden中的缓冲区，并在这个给定的区域内进行指针碰撞，一般单个线程不会填满整个给定的缓冲区

### 垃圾收集器
**Serial收集器**：这款收集器在新生代中使用之前描述的方法进行处理，而在老年代的收集中使用压缩标记清除的方式对于内存进行收集。这里这两种的收集方式都是会STOP-THE-WORLD的方式进行处理，这种方式顾名思义是停止了所有JVM内的线程进展，这使得垃圾收集器能够高效以及完全的模式进行垃圾收集，但是随之而来的问题是垃圾收集的过程中其他的服务进程全部会被停滞，在这个时间段之中会极大的影响响应的速度。（特别是部分响应时间有比较高要求的应用）

Serial收集器对于大多数停顿时间要求不高和在客户端运行的应用中使用比较广泛，它只需几百兆java堆就能有效管理许多应用，并在最差的情况下也能保持比较短暂的停顿。

注：标记压缩方法，在回收老年代的对象的过程中，将存活的对象移到堆的头部，最终收集完成之后所有空余的位置留在尾部，这种方法就可以在之后的内存分配中使用前文所提到过的‘指针碰撞’进行快速的内存分配，在垃圾收集的时候虽然会产生额外的性能消耗，但是显然设计者认为这个设计是值得的。

**Parallel收集器**：这款收集器是以吞吐量为追求的，一般也被称为Throughput收集器，它的操作模式可以说和Serial基本一致，新生代使用Stop-the-world，老年代使用标记压缩。但是它的特色就是使得Minor GC以及Full GC可以在同时进行，也就是将老年代和新生代的垃圾收集进行并发处理，这个提升了垃圾收集的整体效率，所以它能够提供更好的吞吐量的体现。

注：吞吐量值得是在一定时间内对于任务的处理数量，所以我个人将这个视作性能在时间上的积分，而通过提高垃圾收集的时间效率能够降低垃圾收集的时间，减少了应用不能提供服务的整体时间，在系统和硬件条件不变的情况下就能提供更多的吞吐量。



**Mostly-Concurrent收集器**：这种类型的收集器就和之前的非常大的不同了，为了使得系统不至于由于垃圾收集的原因造成较大的延迟波动，所以在耗时较高的老年代垃圾收集中使用了非Stop-the-world的模式，并发标记收集，在正式收集之前就在并发线程中标记好需要收集的内容，只在开始和最后收集执行的时候产生两次简短的停顿。由于在这里收集的时候只需要依照之前的标记进行执行，不需要再进行判断，所以收集的过程停顿时间被降到很低的程度。

但是依然有问题会出现，这种方式的垃圾收集由于是并发进行的，同时代码也在对于内存中的对象进行操作和执行，所以在并发标记阶段将会有不少对象在之后又被改动过，这个时候收集器引入了重新标记的方法，在第一次标记完成之后再对于期间有过个改动的对象进行遍历。为了进一步提高效率重新标记的之前还引入了预清除阶段，预清除阶段会重新标记一些在第一次标记阶段被改掉的对象，这将在重新标记阶段提示效率，减少重新标记产生的停顿。在标记完成之后采用的内存收集的方式并不使用标记-压缩的模式，这个特性使得内存的收集过程也可以和应用的线程是并行的，这进一步减少了停顿的时间。

总体来说CMS收集器的优势在于停顿时间短，但是这个收集器对于性能会有更高的要求，同时由于并发的问题其实并不能被完全避免，垃圾收集的结果难免会漏掉部分需要收集的垃圾，而且由于不使用标记-压缩的模式，导致在之后的内存分配中会有相比其他收集器的额外消耗。

**G1收集器**：Garbage-First收集器是最新的收集器，在概念上颠覆了之前JVM中新生代和老年代的概念。该款收集器将java堆分成相同尺寸的区域，将一组区域标记分为一个带，当然在这里的一组区域可能不连续。

G1收集器的操作方式是将区域中存活的对象转移到另一个区域中去，然后收集前者的区域，G1定期并发标记那些几乎是空的区域，这就是G1的核心思想，使用最小的消耗优先解放区域。

#### 应用对于垃圾收集器的影响
**内存分配**：由于垃圾收集这个任务的性质，可以预见的是当我们的内存中东西过多或者说是溢出的时候我们不得不启动垃圾收集这个过程，内存的大小以及应用中对于内存的使用方式将通过内存使用率极大的影响垃圾收集的频率。

**存活数据多少**：显然垃圾收集器的使用时间是和存活对象的数量有关，越多的对象存活将会使得垃圾收集器需要遍历更多的对象。

**老年代的引用更新**：老年代中引用更新也会需要垃圾收集器额外的注意，所以这也会影响垃圾收集的任务量。

注意，对象池的设计能够在编码的时候提供更多的便利以及种种的好处，但是对于垃圾收集而言，池化的对象显然是Old-to-young引用更新的大户，并且由于池化的原因，这些对象会增加老年代的压力。综上我们在设计应用的时候要考虑到池化对象的优缺点并尽量平衡的使用。


---

## HotSpot JIT编译器

编译指的是从编程完成的代码转化到机器能够是使用的机器码的过程，在这个过程中开发人员可能需要等待很长一段时间才能得到最终可以运行的软件。JAVA采用了另外一种角度来解决这个问题，由于JAVA是基于JVM虚拟机的一种语言，这就使得java可以将编译的过程分为两个步骤。先将代码编译成虚拟机JVM能够看懂的部分(class)，然后再由虚拟机进行动态的将应用执行的class代码动态的转换为机器码并最终执行。

由于这个编译分开的步骤，所以java才真正意义上拥有了一次编译到处运行的优势和特点，因为详细的本地机器码翻译被下放到各个不同环境的JVM中去了，在代码以及初次编译的时候开发人员就不用考虑这个问题。



#### 类继承关系分析
由于在java中类的关系比较复杂，特别是涉及到方法覆盖和重载，优化的过程就会变得比较麻烦，所以在jvm中使用了CHA类型继承关系分析，其基础的思想是只考虑已经加载的子类，并将信息记录在编译代码中，如果执行的过程中有后续的代码覆盖其中的方法时，之前的优化会被丢弃，JVM使用逆优化来解决这个问题。



#### 编译策略
之前有论述将java的编译过程分为两个部分，但是JVM那个部分是在运行的时候才会发生，毕竟JVM是java程序需要运行的时候才会用到的东西，以下的情况也就顺理成章了：JIT没有时间编译所有方法，所有代码最初都是在解释器中运行。

但如果全部都是用解释执行，那么效率将会成为一个很大的问题，所以在JVM中采取了这样的机制：一旦方法被调用的次数比较多，那么这个方法就能得到编译。

具体的执行通过两个方法的计数器方法调用计数器以及回边计数器来完成，方法调用计数器每次调用方法值加一，回边计数器每次代码从后跳转至前加一（循环等步骤）。超过JVM设置的阀值那么这个方法就会得到编译。

一般的过程是这样的，解释器通知JIT编译器执行编译，但是另一方面解释器继续执行代码，直到编译完成之后编译代码会自动关联方法，当然这个部分也可以通过改变JVM中的参数值进行设置。

当长时间的java循环的时候JVM会使用栈上替换的方法，这个操作的关键就是不直接编译方法，而是编译解释器帧，通过直接编译解释器帧的代码使得在循环过程中也能够充分利用编译的成果。



**逆优化**
JVM中还对于编译以及运行有更高的容错机制，那就是逆优化。就是将编译帧转换为解释器的解释帧，这个能将编译过程中的某些乐观优化退回，同时这个过程允许了在编译过程中出现的更大更激进的乐观优化。并且由于在HotSpot中采用方法活跃性的分析法，将逆优化的内存成本极大的降低。



**Client JIT编译器以及Server JIT编译器**
Client JIT编译器的目标是更快的启动以及快速编译，早期的Client JIT编译器就是一个简单快捷的代码生成器，在1.4开始支持非那个发内联，到了1.6有了比较大的改动，基本就是性能提高构架改动等。

Server JIT编译器目标是在应用的稳定运行的时间范围内，将应用的性能推向极致，编译的时候优化幅度大，但是这同样带来了编译成本的提高。

Server JIT编译器的中间代码IR，是一个基于SSA的IR，使用不同的方式展现控制流--程序依赖图。这种方式企图捕获每次执行过程中的最小约束，将其反馈给优化器做出比较大幅度的优化计算。

所有基于JAVA字节码的JIT编译器都需要处理卸载或未初始化的类，Server采用的方式是停止解析并生成罕见陷阱，请求逆优化，然后在下一次编译触发的时候重新编译。

Server JIT对于代码的循环做了大量的优化，循环判断外堤、循环展开、迭代分离。迭代分离将循环转换成3个部分：预循环、主循环、后循环，将主循环所需要的边界判断消除，并直接展开主循环。超字，循环向量化的方式，如循环在内存操作上是线性的，就可以合成一个矢量操作。


---
## Java应用分析技巧
#### 1性能优化机会
大多数的java性能优化都集中于以下几类：

1. 更高效的算法
2. 减少锁争用
3. 为算法生成更有效的代码


#### 2系统或内核态CPU的使用
在理想状态下应用的使用系统态CPU应该是0%，但是对于大多数存在I/O调用需要的应用来说这个目标不现实，所以在这里我们需要降低I/O系统的调用频率，例如使用数据缓存，一大块的数据进行统一的写入和读出等。

我们可以通过各个系统提供的分析应用进行收集目标应用的系统态CPU的使用情况，并可以获得到详细的方法调用，根据方法调用的来源进行查找调用的源头，并尽可能的进行各种优化。

值得注意的是创建BufferedOutputStream的时候可以指定一个可选的缓存大小。Java6中默认的缓存大小是8192如果应用需要写比较大的对象，可以考虑显式的指定使用更大的缓存。并尽量将其设置为操作系统页面大小的整数倍，因为在这个时候操作系统读取缓存的效率最高。

对于存在大量网络I/O的应用程序，降低系统态CPU有另一个方法，可以使用java NIO非阻塞数据结构在java5和6中存在多个对于java NIO性能的改进加入。相对于传统的javaSE阻塞式的数据结构java NIO的编程难度较大，但是只要不超过操作系统的限制，在java NIO中可以写入任意数量的数据。具体的使用哪种情况的网络IO还是要通过具体的应用情况负载和需求来进行判断。

#### 3锁竞争
早期的JVM中锁竞争会导致非常高的系统态CPU使用率，但是现代的JVM即使java应用出现锁竞争也不一定会导致系统态CPU使用率的上升，只有出现了非常严重的锁竞争的时候系统态CPU才会变高。

让步式线程上下文切换是潜在大量锁竞争的征兆，接到通知挂起一个线程或者是唤醒一个线程的动作会导致系统进行让步式上下文切换。

在系统中如果发现使用同步HashMap或者是老版本的hashtable,直接将其换成为新版本的ConcurrentHashMap,同步的HashMap将会导致大量的系统态CPU使用率的上升，ConcurrentHashMap的用户态使用率却可以达到100%

Random作为一个伪随机数的实现比较复杂，所以不需要使用静态的random来进行系统的使用

#### 4volatile的使用
Java对象的volatile字段常用于线程之间状态信息的同步。但是也存在一些副作用，譬如volatile会限制现代JVM JIT编译器对这个字段的优化，volatile字段必须遵守一定的指令顺序。简而言之，volatile字段值在应用的哦所有线程和CPU缓存中必须保持同步。一旦volatile字段值的变化就会触发CPU缓存的更新。

如果在volatile字段上存在大量的CPU高速缓存的未命中并发现对于这个volatile字段有比较多的写操作，这就说明在应用中对于volatile关键字的使用存在一定的问题，但是一个性能稍差的应用比一个错误的实现或者有潜在竞争问题的应用好的多，如果只能如此满足应用的需要，一定的性能牺牲也是可以接受的。

#### 5数据结构大小的调整
StringBuilder和StirngBuffer大小的调整
OpenJDK的实现中使用两倍的增长为他们分配新的数组，老字符串数组的内容会被复制到新字符串中去，然后老字符串数组将会被废弃，显然这个过程需要重新分配，复制和额外的垃圾收集，我们可以通过在一开始进行初始化显式指定大小来避免这些问题。

默认的StringBuffer和StringBuilder仅有16个字符数组的位置，但是在正常使用中这个基本是不会够的，也许使用StringBuilder(int)会比较好的满足应用的性能要求。

Collection类大小的调整
Java Collection类为程序员减轻了大量的编码任务，Collection类的某些实现是基于底层的数组来进行的，比较典型的有HashMap/ArrayList/ConcurrentHashMap等。虽然这些Collection类也含有构造函数可以接受参数作为Collection类的大小，但是一般来说不是特别常用。

与之前的StringBuilder相似在进行调整大小的时候Collection类也需要进行分配新内存，转移的过程，在进行调整的时候有可能将新建的数组和类中的其他字段分配到不同的内存块中，从而在之后的应用中影响性能。并且这个大小的调整会导致CPU高速缓存的未命中。这几个影响比之前提及的StringBuilder大得多。

#### 6增加并行性
单线程的java应用没有办法适应现代增长的CPU和其他硬件线程，那些单线程的应用必须重构之后才能进行多线程的并行工作。

一般来说，如果在单线程中存在一个循环，并且循环的大多数工作也每次循环的迭代无关，那么这可能是重构为多线程版本的一个良好选择。

可以将需要循环执行的内容一分多个使用实现runnables接口的代码块进行处理，这样就可以尽量的使用到多CPU硬件带来的性能优势。

## 第七章 堆内存最佳实践


本章首先介绍了使用jmap命令或者其他工具进行堆转储，然后通过Eclipse Memory Analyze工具分析转储文件，理解浅内存、保留内存、深内存，及EMA的用法。

然后介绍了几种常见的内存溢出场景。

然后从减少内存使用绝度（减小对象大小、延迟初始化、不可变对象和标准化对象、字符串的保留），以及对象生命周期管理（对象重用、弱引用/软引用/其他引用）绝度，讨论了堆内存最佳实践方法。

以上实际都是编程的绝度。



## 第八章 原生内存最佳实践


首先介绍了原生内存使用的理论知识。

在Java8中，通过开启-XX:NativeMemoryTracking=off|summary|detail，然后可以通过命令 jcmd pid VM.native_memory summary查看原生内存使用情况。

介绍了操作系统级别的JVM优化：大页和压缩的OOP。

页是OS管理内存的一个单元，也是OS分配内存的最小单元：要分配一个字节，OS一定会分配一个整页。

介绍了Linux大页和Linux透明大页（从2.6.32开始）：cat(echo always > ) /sys/kernel/mm/transparent_hugepage/enabled

压缩的OOP（ordinary object pointer 普通对象指针），在java7和更新的版本中，只要堆小于32G，压缩的oop默认就是启用的，不用参数-XX:+UseCompressedOops，如果堆大于32G，要大于一定数值，因为需要额外的空间弥补非压缩引用所使用的空间，平均而言，对象引用会占用20%的堆空间，38G是个不错的起点。



## 第九章 线程于同步的性能


拿到这本书后，基于对线程知识的理解（过去看过关于线程的书，查询过很多资料，总结过博客，所以最先看的就是这一章。

本章开始讲了线程池、ThreadPoolExecutor（根据应用场景:CPU/IO密集等，设置最大线程数、最小线程数、线程池任务大小、设置ThreadPoolExecutor大小）、ForkJoinPool、线程同步，以及JVM线程调优（调节线程栈大小、偏向锁、自旋锁、线程优先级）。

最后讲解了线程监视于分析，最常用的是jstack，我们需要数量的看懂jstack的输出结果，并能快速的分析出存在的问题。



## 第十章 Java EE性能调优


本章介绍了一些Java EE技术，及常见的调优，比如Servlet、Jsp、Http、EJB（过时的技术）、数据交换技术（XML、JSON）、对象序列化、数据传输（Http、WebService、RESTFull）

本章，个人觉得，其他简单看看，着重看看对象序列化就行了。



## 第十一章 数据库性能的最佳实践


本章所讲的理论，更像是数据库相关的理论。

在日常的应用开发中，关于数据库相关，我们往往是应用持久化框架，所以从开发绝度考虑DB性能调优，更多的是在持久化框架配置方面。
